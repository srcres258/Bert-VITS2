{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengXing15646/Bert-VITS2/blob/master/bert_vits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrP7wZaqtVi7",
    "outputId": "36f7279f-dc58-428d-d55f-46abcf93fc53"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Bert-VITS2'...\n",
      "remote: Enumerating objects: 1299, done.\u001b[K\n",
      "remote: Counting objects: 100% (726/726), done.\u001b[K\n",
      "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
      "remote: Total 1299 (delta 589), reused 538 (delta 473), pack-reused 573\u001b[K\n",
      "Receiving objects: 100% (1299/1299), 5.56 MiB | 14.20 MiB/s, done.\n",
      "Resolving deltas: 100% (765/765), done.\n"
     ]
    }
   ],
   "source": [
    "# 克隆代码仓库\n",
    "!git clone https://github.com/MengXing15646/Bert-VITS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzXJQQ16t4DK",
    "outputId": "3c774eca-7739-434e-e73a-698dc47539cc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 安装cuda，对应版本为11.8\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ulDyNNzwyrY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e62dbd4-dac6-4fa5-fcd8-ccbf66455d0b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/Bert-VITS2\n",
      "Collecting librosa==0.9.1 (from -r requirements.txt (line 1))\n",
      "  Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.56.4)\n",
      "Collecting phonemizer (from -r requirements.txt (line 5))\n",
      "  Downloading phonemizer-3.2.1-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.11.3)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.13.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.15.2+cu118)\n",
      "Collecting Unidecode (from -r requirements.txt (line 10))\n",
      "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting amfm_decompy (from -r requirements.txt (line 11))\n",
      "  Downloading AMFM_decompy-1.0.11.tar.gz (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.5/751.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.42.1)\n",
      "Collecting transformers (from -r requirements.txt (line 13))\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypinyin (from -r requirements.txt (line 14))\n",
      "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cn2an (from -r requirements.txt (line 15))\n",
      "  Downloading cn2an-0.5.22-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio (from -r requirements.txt (line 16))\n",
      "  Downloading gradio-3.47.1-py3-none-any.whl (20.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting av (from -r requirements.txt (line 17))\n",
      "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mecab-python3 (from -r requirements.txt (line 18))\n",
      "  Downloading mecab_python3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting loguru (from -r requirements.txt (line 19))\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting unidic-lite (from -r requirements.txt (line 20))\n",
      "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting cmudict (from -r requirements.txt (line 21))\n",
      "  Downloading cmudict-1.0.13-py3-none-any.whl (939 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fugashi (from -r requirements.txt (line 22))\n",
      "  Downloading fugashi-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting num2words (from -r requirements.txt (line 23))\n",
      "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (4.4.2)\n",
      "Collecting resampy>=0.2.2 (from librosa==0.9.1->-r requirements.txt (line 1))\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 4)) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 4)) (67.7.2)\n",
      "Collecting segments (from phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading segments-2.2.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer->-r requirements.txt (line 5)) (23.1.0)\n",
      "Collecting dlinfo (from phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from phonemizer->-r requirements.txt (line 5)) (4.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.41.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (17.0.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 13))\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (2023.6.3)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers->-r requirements.txt (line 13))\n",
      "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 13))\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (4.66.1)\n",
      "Collecting proces>=0.1.3 (from cn2an->-r requirements.txt (line 15))\n",
      "  Downloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 16)) (4.2.2)\n",
      "Collecting fastapi (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting gradio-client==0.6.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading gradio_client-0.6.0-py3-none-any.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 16)) (6.1.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 16)) (2.1.3)\n",
      "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 16)) (1.5.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 16)) (1.10.13)\n",
      "Collecting pydub (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.0->gradio->-r requirements.txt (line 16)) (2023.6.0)\n",
      "Collecting importlib-metadata<6.0.0,>=5.1.0 (from cmudict->-r requirements.txt (line 21))\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio->-r requirements.txt (line 16))\n",
      "  Downloading importlib_resources-5.13.0-py3-none-any.whl (32 kB)\n",
      "Collecting docopt>=0.6.2 (from num2words->-r requirements.txt (line 23))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (4.19.1)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (0.12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->cmudict->-r requirements.txt (line 21)) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 16)) (2023.3.post1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 13))\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 16)) (8.1.7)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 16))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 16)) (3.7.1)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 16))\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r requirements.txt (line 16))\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 16)) (1.3.0)\n",
      "Collecting clldutils>=1.7.3 (from segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading clldutils-3.20.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting csvw>=1.5.6 (from segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading csvw-3.1.3-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->-r requirements.txt (line 16)) (1.1.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (0.9.0)\n",
      "Collecting colorlog (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pylatexenc (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (4.9.3)\n",
      "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (2.13.0)\n",
      "Collecting colorama (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting isodate (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting language-tags (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rdflib (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5))\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (4.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 16)) (0.10.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 7)) (3.2.2)\n",
      "Building wheels for collected packages: amfm_decompy, unidic-lite, docopt, ffmpy, pylatexenc\n",
      "  Building wheel for amfm_decompy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for amfm_decompy: filename=AMFM_decompy-1.0.11-py3-none-any.whl size=42835 sha256=cfe8ca3e0bb583c3681154feba2c596e723ca5e85b1d2e11a81ce1fa32287676\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/81/e7/443ad333f2f4ed8c06fc027caeb0d0c84b896fe7e56c2e92b1\n",
      "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658816 sha256=5bd5d17baa464230669c502d8789b25762b0c49d3a542aa41ff4fc5978c2be62\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=42041cc7d3667f67359451a40de70ccc701e637b486bb7cbb1d6364f5676829c\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=2af94d286a7bcecdb07b0edf305b739fb93129189d56d8e6667a383adcf4eb65\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136818 sha256=34001360a0f98e00ed6871fc684adbb5724fa108628e20b3a20339f11d329770\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
      "Successfully built amfm_decompy unidic-lite docopt ffmpy pylatexenc\n",
      "Installing collected packages: unidic-lite, safetensors, rfc3986, pylatexenc, pydub, mecab-python3, language-tags, ffmpy, docopt, dlinfo, av, websockets, Unidecode, semantic-version, python-multipart, pypinyin, proces, orjson, num2words, loguru, isodate, importlib-resources, importlib-metadata, h11, fugashi, colorlog, colorama, aiofiles, uvicorn, starlette, resampy, rdflib, huggingface-hub, httpcore, cn2an, cmudict, clldutils, amfm_decompy, tokenizers, librosa, httpx, fastapi, transformers, gradio-client, csvw, segments, gradio, phonemizer\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 6.1.0\n",
      "    Uninstalling importlib-resources-6.1.0:\n",
      "      Successfully uninstalled importlib-resources-6.1.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.8.0\n",
      "    Uninstalling importlib-metadata-6.8.0:\n",
      "      Successfully uninstalled importlib-metadata-6.8.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.1\n",
      "    Uninstalling librosa-0.10.1:\n",
      "      Successfully uninstalled librosa-0.10.1\n",
      "Successfully installed Unidecode-1.3.7 aiofiles-23.2.1 amfm_decompy-1.0.11 av-10.0.0 clldutils-3.20.0 cmudict-1.0.13 cn2an-0.5.22 colorama-0.4.6 colorlog-6.7.0 csvw-3.1.3 dlinfo-1.2.1 docopt-0.6.2 fastapi-0.103.2 ffmpy-0.3.1 fugashi-1.3.0 gradio-3.47.1 gradio-client-0.6.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.16.4 importlib-metadata-5.2.0 importlib-resources-5.13.0 isodate-0.6.1 language-tags-1.2.0 librosa-0.9.1 loguru-0.7.2 mecab-python3-1.0.8 num2words-0.5.12 orjson-3.9.7 phonemizer-3.2.1 proces-0.1.7 pydub-0.25.1 pylatexenc-2.10 pypinyin-0.49.0 python-multipart-0.0.6 rdflib-7.0.0 resampy-0.4.2 rfc3986-1.5.0 safetensors-0.3.3 segments-2.2.1 semantic-version-2.10.0 starlette-0.27.0 tokenizers-0.14.0 transformers-4.34.0 unidic-lite-1.0.8 uvicorn-0.23.2 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "# 安装所需要的依赖\n",
    "%cd /content/Bert-VITS2/\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwvOeR-u09yA",
    "outputId": "759a0aa8-621c-4c08-f3b2-632c50fadaac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/.gitattributes\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/README.md\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/added_tokens.json\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/config.json\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/flax_model.msgpack\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/special_tokens_map.json\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tf_model.h5\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tokenizer.json\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tokenizer_config.json\n",
      "https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# 将hugging face的模型文件二次分发直链\n",
    "from huggingface_hub import hf_hub_url\n",
    "from huggingface_hub.utils import filter_repo_objects\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "\n",
    "repo_id = \"hfl/chinese-roberta-wwm-ext-large\"\n",
    "repo_type = \"model\"\n",
    "# 如果是数据 dataset\n",
    "\n",
    "repo_info = HfApi().repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "# 有时候会连接Error，多试几次\n",
    "files = list(filter_repo_objects(items=[f.rfilename for f in repo_info.siblings]))\n",
    "urls = [hf_hub_url(repo_id, filename=file, repo_type=repo_type) for file in files]\n",
    "print(\"\\n\".join(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odI2jOJq3ANx",
    "outputId": "27dc043b-b06c-4189-bf92-3c7cdedc7702"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-10-06 06:27:41--  https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/flax_model.msgpack\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.88, 18.172.134.4, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/a46a510fe646213c728b80c9d0d5691d05235523d67f9ac3c3ce4e67deabf926?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flax_model.msgpack%3B+filename%3D%22flax_model.msgpack%22%3B&Expires=1696832861&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvYTQ2YTUxMGZlNjQ2MjEzYzcyOGI4MGM5ZDBkNTY5MWQwNTIzNTUyM2Q2N2Y5YWMzYzNjZTRlNjdkZWFiZjkyNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=l2Y74wJdPr3Rcb4Fgn-%7ENGxNaZ8fnc9zPPQ%7EEEhb5UbYRMAzEFyPiGvFhJbqOgJsE7p-W7Pt45PTbpb%7EUEzloqqpTIsw-p8Bv4I-w6lNFo2iTxD2lsCrf7wW25XlPj3cKSH-apG8mw-ebwUwtVYqTDc6uGmTrkxGMeJDlvbd7xfPLIPAIR3JQTJqLu6kyXKA6lLV658L9X4IfEOGoKTzUYZwj5tmbh6Qc17mXiwQcHoUzTrLbzR%7E7yzONw6ngzoQtVhUr9kKvV4SxcTogSSTEbTE5zaBaGz6C0rX1hdgG9fLhrpo3VhsLvKq8KkqtvyuFiVtPCBqedCVST5dwaNUXQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:27:41--  https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/a46a510fe646213c728b80c9d0d5691d05235523d67f9ac3c3ce4e67deabf926?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flax_model.msgpack%3B+filename%3D%22flax_model.msgpack%22%3B&Expires=1696832861&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvYTQ2YTUxMGZlNjQ2MjEzYzcyOGI4MGM5ZDBkNTY5MWQwNTIzNTUyM2Q2N2Y5YWMzYzNjZTRlNjdkZWFiZjkyNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=l2Y74wJdPr3Rcb4Fgn-%7ENGxNaZ8fnc9zPPQ%7EEEhb5UbYRMAzEFyPiGvFhJbqOgJsE7p-W7Pt45PTbpb%7EUEzloqqpTIsw-p8Bv4I-w6lNFo2iTxD2lsCrf7wW25XlPj3cKSH-apG8mw-ebwUwtVYqTDc6uGmTrkxGMeJDlvbd7xfPLIPAIR3JQTJqLu6kyXKA6lLV658L9X4IfEOGoKTzUYZwj5tmbh6Qc17mXiwQcHoUzTrLbzR%7E7yzONw6ngzoQtVhUr9kKvV4SxcTogSSTEbTE5zaBaGz6C0rX1hdgG9fLhrpo3VhsLvKq8KkqtvyuFiVtPCBqedCVST5dwaNUXQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.26, 18.154.185.27, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1302196529 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘bert/chinese-roberta-wwm-ext-large/flax_model.msgpack’\n",
      "\n",
      "flax_model.msgpack  100%[===================>]   1.21G   245MB/s    in 5.1s    \n",
      "\n",
      "2023-10-06 06:27:46 (243 MB/s) - ‘bert/chinese-roberta-wwm-ext-large/flax_model.msgpack’ saved [1302196529/1302196529]\n",
      "\n",
      "--2023-10-06 06:27:47--  https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.88, 18.172.134.4, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/4ac62d49144d770c5ca9a5d1d3039c4995665a080febe63198189857c6bd11cd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1696832867&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvNGFjNjJkNDkxNDRkNzcwYzVjYTlhNWQxZDMwMzljNDk5NTY2NWEwODBmZWJlNjMxOTgxODk4NTdjNmJkMTFjZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=AwaP%7EPaveJukoWKVmPlrfqEiKT7Jsxo1Emj02%7EpXjqyrhSAkPw3hc6D5xWtmc0pg8krL5NqZs0as8Rl4NtXqRJ3w3siXxZGMuCPzNsEgN380DO0aBpHJmO38viaHZ284-cg1g3fNPUiDzSKwIjcwDkkZrgQTyh5RAQaASPVVv7zZIWwulw%7ETrcmeZKYBn16DKa5PzA5K7oeFOLzdDns4qBkjzf-dILmdZgOc%7ETviC2evQ-O0f0rXjD-cMFmgfcADW8mP74Tt0adtFfrnwI%7E%7E%7EEHyfYD55cNWNVVRAscH2N3ecuUXD2m2WVIBNu1xbr0GkojlolbqionLaGj9mLcj6g__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:27:47--  https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/4ac62d49144d770c5ca9a5d1d3039c4995665a080febe63198189857c6bd11cd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1696832867&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvNGFjNjJkNDkxNDRkNzcwYzVjYTlhNWQxZDMwMzljNDk5NTY2NWEwODBmZWJlNjMxOTgxODk4NTdjNmJkMTFjZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=AwaP%7EPaveJukoWKVmPlrfqEiKT7Jsxo1Emj02%7EpXjqyrhSAkPw3hc6D5xWtmc0pg8krL5NqZs0as8Rl4NtXqRJ3w3siXxZGMuCPzNsEgN380DO0aBpHJmO38viaHZ284-cg1g3fNPUiDzSKwIjcwDkkZrgQTyh5RAQaASPVVv7zZIWwulw%7ETrcmeZKYBn16DKa5PzA5K7oeFOLzdDns4qBkjzf-dILmdZgOc%7ETviC2evQ-O0f0rXjD-cMFmgfcADW8mP74Tt0adtFfrnwI%7E%7E%7EEHyfYD55cNWNVVRAscH2N3ecuUXD2m2WVIBNu1xbr0GkojlolbqionLaGj9mLcj6g__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.27, 18.154.185.64, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1306484351 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘bert/chinese-roberta-wwm-ext-large/pytorch_model.bin’\n",
      "\n",
      "pytorch_model.bin   100%[===================>]   1.22G   226MB/s    in 5.0s    \n",
      "\n",
      "2023-10-06 06:27:52 (251 MB/s) - ‘bert/chinese-roberta-wwm-ext-large/pytorch_model.bin’ saved [1306484351/1306484351]\n",
      "\n",
      "--2023-10-06 06:27:52--  https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tf_model.h5\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.88, 18.172.134.4, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/72d18616fb285b720cb869c25aa9f4d7371033dfd5d8ba82aca448fdd28132bf?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tf_model.h5%3B+filename%3D%22tf_model.h5%22%3B&Expires=1696832872&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvNzJkMTg2MTZmYjI4NWI3MjBjYjg2OWMyNWFhOWY0ZDczNzEwMzNkZmQ1ZDhiYTgyYWNhNDQ4ZmRkMjgxMzJiZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=or1K2pPmoIGib9xT9gegBxolCJwD9r7XjdMmhjVtwv0mb7EkReQpCC2zNMUIiLm3hALfecHGcdgBgaXGoyI7uJOktaOg-xXmZJ02mJz-S436dXRQSlyGPyLJWtWuugAAe4vjScOpkET1zyxxECS7UXVdWmceH79qMM2KmItdxlAzbWdX1prx65WImHITBB4GU1cCuJvD2ARbeCu7AT-kZc2pviw-1%7EIxztdjYtFfcyJgw8tFhLormqV02vrq13SnqA1Nq4POZQNLCLajdsAtd871smEfiQs0BI1FfG7wg-b9qvU8dSpfH0cWsO6RbIWNZ3XWybs4LQcGanSUj2De6Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:27:52--  https://cdn-lfs.huggingface.co/hfl/chinese-roberta-wwm-ext-large/72d18616fb285b720cb869c25aa9f4d7371033dfd5d8ba82aca448fdd28132bf?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tf_model.h5%3B+filename%3D%22tf_model.h5%22%3B&Expires=1696832872&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjg3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9oZmwvY2hpbmVzZS1yb2JlcnRhLXd3bS1leHQtbGFyZ2UvNzJkMTg2MTZmYjI4NWI3MjBjYjg2OWMyNWFhOWY0ZDczNzEwMzNkZmQ1ZDhiYTgyYWNhNDQ4ZmRkMjgxMzJiZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=or1K2pPmoIGib9xT9gegBxolCJwD9r7XjdMmhjVtwv0mb7EkReQpCC2zNMUIiLm3hALfecHGcdgBgaXGoyI7uJOktaOg-xXmZJ02mJz-S436dXRQSlyGPyLJWtWuugAAe4vjScOpkET1zyxxECS7UXVdWmceH79qMM2KmItdxlAzbWdX1prx65WImHITBB4GU1cCuJvD2ARbeCu7AT-kZc2pviw-1%7EIxztdjYtFfcyJgw8tFhLormqV02vrq13SnqA1Nq4POZQNLCLajdsAtd871smEfiQs0BI1FfG7wg-b9qvU8dSpfH0cWsO6RbIWNZ3XWybs4LQcGanSUj2De6Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.27, 18.154.185.64, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1302594480 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘bert/chinese-roberta-wwm-ext-large/tf_model.h5’\n",
      "\n",
      "tf_model.h5         100%[===================>]   1.21G   172MB/s    in 8.0s    \n",
      "\n",
      "2023-10-06 06:28:00 (155 MB/s) - ‘bert/chinese-roberta-wwm-ext-large/tf_model.h5’ saved [1302594480/1302594480]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过直链下载必要的模型文件\n",
    "!wget -P bert/chinese-roberta-wwm-ext-large/ https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/flax_model.msgpack\n",
    "!wget -P bert/chinese-roberta-wwm-ext-large/ https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
    "!wget -P bert/chinese-roberta-wwm-ext-large/ https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tf_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 分发底模直链\n",
    "from huggingface_hub import hf_hub_url\n",
    "from huggingface_hub.utils import filter_repo_objects\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "\n",
    "repo_id = \"Erythrocyte/bert-vits2_base_model\"\n",
    "repo_type = \"model\"\n",
    "# 如果是数据 dataset\n",
    "\n",
    "repo_info = HfApi().repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "# 有时候会连接Error，多试几次\n",
    "files = list(filter_repo_objects(items=[f.rfilename for f in repo_info.siblings]))\n",
    "urls = [hf_hub_url(repo_id, filename=file, repo_type=repo_type) for file in files]\n",
    "print(\"\\n\".join(urls))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3E44vBwao19",
    "outputId": "3655f9ba-d93f-48e7-8854-9d500b6395ed"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/.gitattributes\n",
      "https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/DUR_0.pth\n",
      "https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/D_0.pth\n",
      "https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/G_0.pth\n",
      "https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/README.md\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 下载底模文件\n",
    "!wget -P logs/ztt/ https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/DUR_0.pth\n",
    "!wget -P logs/ztt/ https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/D_0.pth\n",
    "!wget -P logs/ztt/ https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/G_0.pth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POzjP8uPaxtu",
    "outputId": "e89ea942-9e30-4e82-94a7-6bd6bfc7455a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-10-06 06:28:22--  https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/DUR_0.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.24, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/9b10d56699967ed5c6cdb167de3310ae47eacbe039bbea4235a9a4958d871c4a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27DUR_0.pth%3B+filename%3D%22DUR_0.pth%22%3B&Expires=1696831630&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMTYzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzliMTBkNTY2OTk5NjdlZDVjNmNkYjE2N2RlMzMxMGFlNDdlYWNiZTAzOWJiZWE0MjM1YTlhNDk1OGQ4NzFjNGE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=jndsqbZE-FxWTQiAgzaivCPuztfqZudFFmvkGSQ62L7oHF9WPxJF%7ElCBBAZKTRgEuXWE%7EBoEmnCCl%7EMEpYDqs5xQRcJEuap22EuaL97U6q5gNZYjD3r3tFPS1Z6DLr4QKW%7ER9J8fn13exxk4htTHFPd9OB7MOHvq%7EV5UTFIAnfuZ2a9uUG4RoBo3wryVK16ZgJOsVRoLu8hDFZhzSW9vxQgTQ8vdcHGLBCIdeCa2ioOynO3PszSvDM6b1CynU93gFP3LI4oRrUP%7EfD05%7EFhqLUo2CKRZclCGAdjcOWnC7Pd1igrpq38%7EvZYVsFtuBsZjjzSR0DT1tbLPkSkWZ4fgrA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:28:22--  https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/9b10d56699967ed5c6cdb167de3310ae47eacbe039bbea4235a9a4958d871c4a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27DUR_0.pth%3B+filename%3D%22DUR_0.pth%22%3B&Expires=1696831630&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMTYzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzliMTBkNTY2OTk5NjdlZDVjNmNkYjE2N2RlMzMxMGFlNDdlYWNiZTAzOWJiZWE0MjM1YTlhNDk1OGQ4NzFjNGE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=jndsqbZE-FxWTQiAgzaivCPuztfqZudFFmvkGSQ62L7oHF9WPxJF%7ElCBBAZKTRgEuXWE%7EBoEmnCCl%7EMEpYDqs5xQRcJEuap22EuaL97U6q5gNZYjD3r3tFPS1Z6DLr4QKW%7ER9J8fn13exxk4htTHFPd9OB7MOHvq%7EV5UTFIAnfuZ2a9uUG4RoBo3wryVK16ZgJOsVRoLu8hDFZhzSW9vxQgTQ8vdcHGLBCIdeCa2ioOynO3PszSvDM6b1CynU93gFP3LI4oRrUP%7EfD05%7EFhqLUo2CKRZclCGAdjcOWnC7Pd1igrpq38%7EvZYVsFtuBsZjjzSR0DT1tbLPkSkWZ4fgrA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.64, 18.154.185.26, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6886407 (6.6M) [binary/octet-stream]\n",
      "Saving to: ‘logs/ztt/DUR_0.pth’\n",
      "\n",
      "DUR_0.pth           100%[===================>]   6.57M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-10-06 06:28:23 (46.9 MB/s) - ‘logs/ztt/DUR_0.pth’ saved [6886407/6886407]\n",
      "\n",
      "--2023-10-06 06:28:23--  https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/D_0.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.24, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/22d903783544badbdd31254c3c1b6f80a27f63204fb5242d0e62eb22ba924d29?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27D_0.pth%3B+filename%3D%22D_0.pth%22%3B&Expires=1696832903&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjkwM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzIyZDkwMzc4MzU0NGJhZGJkZDMxMjU0YzNjMWI2ZjgwYTI3ZjYzMjA0ZmI1MjQyZDBlNjJlYjIyYmE5MjRkMjk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=R0aIfPbVSpkxSqeELl307c9LdOse5xgfDRBdAwHFcdsk--%7EW5z9x2Njk2WQC-cWKHUfJntAB1Xckb2taCT-fs8hedMlRnOK71m3X4zNvfwcX1Yrcilps8WvBzMlEFcKW8HGCrxO-PzYXFRmK9sGqW6Vd74jcIdvWBJyRwvs1SwvkctVmPx8WJ2gyADl3wwXVFIeDqxWl85%7EtMXKPFqX9G72Z38sZAEQ-jollgQbSforQbEXq7UFetKQtI4yd-trr5BUxGxn3%7Ejt4WSLv9rRPa-OM7drO0xHRAWmdwQElFyaNt1z6XpozNuRas1KKtBZEGnOXZJiv1Kpm4vUUSgZWoQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:28:23--  https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/22d903783544badbdd31254c3c1b6f80a27f63204fb5242d0e62eb22ba924d29?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27D_0.pth%3B+filename%3D%22D_0.pth%22%3B&Expires=1696832903&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjkwM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzIyZDkwMzc4MzU0NGJhZGJkZDMxMjU0YzNjMWI2ZjgwYTI3ZjYzMjA0ZmI1MjQyZDBlNjJlYjIyYmE5MjRkMjk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=R0aIfPbVSpkxSqeELl307c9LdOse5xgfDRBdAwHFcdsk--%7EW5z9x2Njk2WQC-cWKHUfJntAB1Xckb2taCT-fs8hedMlRnOK71m3X4zNvfwcX1Yrcilps8WvBzMlEFcKW8HGCrxO-PzYXFRmK9sGqW6Vd74jcIdvWBJyRwvs1SwvkctVmPx8WJ2gyADl3wwXVFIeDqxWl85%7EtMXKPFqX9G72Z38sZAEQ-jollgQbSforQbEXq7UFetKQtI4yd-trr5BUxGxn3%7Ejt4WSLv9rRPa-OM7drO0xHRAWmdwQElFyaNt1z6XpozNuRas1KKtBZEGnOXZJiv1Kpm4vUUSgZWoQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.64, 18.154.185.26, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 561072913 (535M) [binary/octet-stream]\n",
      "Saving to: ‘logs/ztt/D_0.pth’\n",
      "\n",
      "D_0.pth             100%[===================>] 535.08M   233MB/s    in 2.3s    \n",
      "\n",
      "2023-10-06 06:28:25 (233 MB/s) - ‘logs/ztt/D_0.pth’ saved [561072913/561072913]\n",
      "\n",
      "--2023-10-06 06:28:25--  https://huggingface.co/Erythrocyte/bert-vits2_base_model/resolve/main/G_0.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.24, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/597ad6d0d7d6cc56a7a56a43455ba2f8343c0b51db3a5b8c99052352ef542086?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27G_0.pth%3B+filename%3D%22G_0.pth%22%3B&Expires=1696832905&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjkwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzU5N2FkNmQwZDdkNmNjNTZhN2E1NmE0MzQ1NWJhMmY4MzQzYzBiNTFkYjNhNWI4Yzk5MDUyMzUyZWY1NDIwODY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=IqiTKfiz%7EiLvkbIpmSTPwl0HhiMSXim5y75WuJ6WcAAVLk74Et5cstN1K4G7wtEDePQip1W9FyeK9kv3sgik7D4BMpEi-1tV6g5xDR52CsUi2EwgCihmXSczgKgLJzeknCRRbXe7s5XbuvhIXRxZSN9T7FhecgDBt05jOSkBjPNDuwyURm8ThMxMMYHSRNzaoMJtaQ2iuLZch5QSXfp%7E8ntjRQg9033UZ5QNwvxTATiGw1aqnzK%7Ek6PZdspB1MlajSn73llw0daLi-FRkQ-2M2tU7%7EZR5rtf8%7E5f1IpU035PiwavU3iwz5b3jdVqZXE0yWddJ-DgcK1iP8CBJQ2N5g__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-10-06 06:28:25--  https://cdn-lfs.huggingface.co/repos/69/63/6963c29b1514546387f7031670d5375efc3ab3c4e844660404b14028b51aafa0/597ad6d0d7d6cc56a7a56a43455ba2f8343c0b51db3a5b8c99052352ef542086?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27G_0.pth%3B+filename%3D%22G_0.pth%22%3B&Expires=1696832905&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjgzMjkwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82OS82My82OTYzYzI5YjE1MTQ1NDYzODdmNzAzMTY3MGQ1Mzc1ZWZjM2FiM2M0ZTg0NDY2MDQwNGIxNDAyOGI1MWFhZmEwLzU5N2FkNmQwZDdkNmNjNTZhN2E1NmE0MzQ1NWJhMmY4MzQzYzBiNTFkYjNhNWI4Yzk5MDUyMzUyZWY1NDIwODY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=IqiTKfiz%7EiLvkbIpmSTPwl0HhiMSXim5y75WuJ6WcAAVLk74Et5cstN1K4G7wtEDePQip1W9FyeK9kv3sgik7D4BMpEi-1tV6g5xDR52CsUi2EwgCihmXSczgKgLJzeknCRRbXe7s5XbuvhIXRxZSN9T7FhecgDBt05jOSkBjPNDuwyURm8ThMxMMYHSRNzaoMJtaQ2iuLZch5QSXfp%7E8ntjRQg9033UZ5QNwvxTATiGw1aqnzK%7Ek6PZdspB1MlajSn73llw0daLi-FRkQ-2M2tU7%7EZR5rtf8%7E5f1IpU035PiwavU3iwz5b3jdVqZXE0yWddJ-DgcK1iP8CBJQ2N5g__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.64, 18.154.185.26, 18.154.185.94, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 621434333 (593M) [binary/octet-stream]\n",
      "Saving to: ‘logs/ztt/G_0.pth’\n",
      "\n",
      "G_0.pth             100%[===================>] 592.65M   233MB/s    in 2.5s    \n",
      "\n",
      "2023-10-06 06:28:28 (233 MB/s) - ‘logs/ztt/G_0.pth’ saved [621434333/621434333]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFGXmqIAH2Wq",
    "outputId": "2285e96e-ebd4-45e9-abbf-03351f0b784b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./raw/.ipynb_checkpoints\n",
      "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
      "./raw/ztt\n",
      "198it [00:04, 46.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# 重采样\n",
    "!python resample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2iNn5ubFJl-",
    "outputId": "f9711fc9-cad3-44ad-8e9c-b82f4c6489bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  0% 0/196 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.759 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100% 196/196 [00:01<00:00, 124.40it/s]\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ha7RWAfImjo",
    "outputId": "0b4b505b-3ba3-4aa5-f8dc-d2f69181b5d5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\r  0% 0/196 [00:00<?, ?it/s]Some weights of the model checkpoint at ./bert/chinese-roberta-wwm-ext-large were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ./bert/chinese-roberta-wwm-ext-large were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100% 196/196 [00:30<00:00,  6.38it/s]\n"
     ]
    }
   ],
   "source": [
    "!python bert_gen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKXsHYQTV8jJ",
    "outputId": "2206857a-e942-4207-b3c6-0e57bbefbf3e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2023-10-06 06:32:06.730623: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-06 06:32:08.403269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[32m2023-10-06 06:32:12.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mInit dataset...\u001b[0m\n",
      "100% 192/192 [00:00<00:00, 48788.71it/s]\n",
      "\u001b[32m2023-10-06 06:32:12.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mskipped: 8, total: 192\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[32m2023-10-06 06:32:12.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mInit dataset...\u001b[0m\n",
      "100% 4/4 [00:00<00:00, 34952.53it/s]\n",
      "\u001b[32m2023-10-06 06:32:12.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mskipped: 0, total: 4\u001b[0m\n",
      "Using noise scaled MAS for VITS2\n",
      "Using duration discriminator for VITS2\n",
      "INFO:ztt:Loaded checkpoint './logs/ztt/DUR_0.pth' (iteration 0)\n",
      "ERROR:ztt:enc_p.emb.weight is not in the checkpoint\n",
      "WARNING:ztt:Seems you are using the old version of the model, the enc_p.ja_bert_proj.weight is automatically set to zero for backward compatibility\n",
      "WARNING:ztt:Seems you are using the old version of the model, the enc_p.ja_bert_proj.bias is automatically set to zero for backward compatibility\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.3.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.4.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.attn_layers.5.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_1.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.3.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.3.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.3.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.3.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.4.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.4.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.4.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.4.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.5.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.5.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.5.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.ffn_layers.5.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.0.enc.norm_layers_2.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.3.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.4.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.attn_layers.5.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_1.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.3.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.3.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.3.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.3.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.4.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.4.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.4.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.4.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.5.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.5.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.5.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.ffn_layers.5.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.2.enc.norm_layers_2.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.3.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.4.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.attn_layers.5.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_1.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.3.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.3.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.3.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.3.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.4.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.4.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.4.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.4.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.5.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.5.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.5.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.ffn_layers.5.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.4.enc.norm_layers_2.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.3.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.4.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.emb_rel_k is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.emb_rel_v is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_q.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_q.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_k.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_k.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_v.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_v.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_o.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.attn_layers.5.conv_o.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_1.5.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.3.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.3.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.3.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.3.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.4.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.4.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.4.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.4.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.5.conv_1.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.5.conv_1.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.5.conv_2.weight is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.ffn_layers.5.conv_2.bias is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.3.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.3.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.4.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.4.beta is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.5.gamma is not in the checkpoint\n",
      "ERROR:ztt:flow.flows.6.enc.norm_layers_2.5.beta is not in the checkpoint\n",
      "INFO:ztt:Loaded checkpoint './logs/ztt/G_0.pth' (iteration 0)\n",
      "INFO:ztt:Loaded checkpoint './logs/ztt/D_0.pth' (iteration 0)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/content/Bert-VITS2/mel_processing.py:83: FutureWarning: Pass sr=44100, n_fft=2048, n_mels=128, fmin=0.0, fmax=None as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [1, 9, 96], strides() = [132960, 96, 1]\n",
      "bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "INFO:ztt:Train Epoch: 1 [0%]\n",
      "INFO:ztt:[2.506504535675049, 2.8505849838256836, 5.078285217285156, 24.900754928588867, 3.6789870262145996, 239.40631103515625, 0, 0.0003]\n",
      "Evaluating ...\n",
      "INFO:ztt:Saving model and optimizer state at iteration 1 to ./logs/ztt/G_0.pth\n",
      "INFO:ztt:Saving model and optimizer state at iteration 1 to ./logs/ztt/D_0.pth\n",
      "INFO:ztt:Saving model and optimizer state at iteration 1 to ./logs/ztt/DUR_0.pth\n",
      "4it [01:23, 20.88s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/Bert-VITS2/train_ms.py\", line 598, in <module>\n",
      "    run()\n",
      "  File \"/content/Bert-VITS2/train_ms.py\", line 226, in run\n",
      "    train_and_evaluate(\n",
      "  File \"/content/Bert-VITS2/train_ms.py\", line 403, in train_and_evaluate\n",
      "    scaler.scale(loss_gen_all).backward()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!python train_ms.py -m ztt -c configs/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4jVpaS8sax2",
    "outputId": "e99104e2-35a3-4c85-f3e1-58cef2a4998e"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| numexpr.utils | INFO | NumExpr defaulting to 2 threads.\n",
      "| utils | INFO | Loaded checkpoint './logs/ztt/G_0.pth' (iteration 1)\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://2e7ec2e0ab538d5534.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Building prefix dict from the default dictionary ...\n",
      "| jieba | DEBUG | Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "| jieba | DEBUG | Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.753 seconds.\n",
      "| jieba | DEBUG | Loading model cost 0.753 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "| jieba | DEBUG | Prefix dict has been built successfully.\n",
      "Some weights of the model checkpoint at ./bert/chinese-roberta-wwm-ext-large were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ./bert/chinese-roberta-wwm-ext-large were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ./bert/chinese-roberta-wwm-ext-large were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:183: UserWarning: Trying to convert audio automatically from float64 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "!python webui.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}